{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### Default Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "train_origin_data = 'data.orig'\n",
    "train_annotated_data = 'annotation.man.af'\n",
    "entity_type_list = [\"d\", \"s\", \"c\", \"i\", \"a\", \"b\", \"t\", \"p\"]\n",
    "all_data = [\"raw_data.orig\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_line(line_num, origin_line, line, entity_type_list):\n",
    "    words = []\n",
    "    tags = []\n",
    "    for part in line.split(\" \"):\n",
    "        part = part.strip(\"\\n\")\n",
    "        if len(part) >= 2 and part[-2] == '\\\\' and part[-1] in entity_type_list:\n",
    "            words.extend(list(part[ :-2]))\n",
    "            part_tag = [\"B-\" + part[-1].upper()] + [\"I-\" + part[-1].upper()] * (len(part) - 3)\n",
    "            tags.extend(part_tag)\n",
    "        else:\n",
    "            words.extend(list(part))\n",
    "            part_tag = [\"O\"] * len(part)\n",
    "            tags.extend(part_tag)\n",
    "    assert len(words) == len(tags)\n",
    "    if(list(origin_line.strip()) != words):\n",
    "        print(\"At line {} origin and annotated line don't match! \".format(line_num))\n",
    "    assert words == list(origin_line.strip())\n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpora(data_path, train_origin_data,train_annotated_data,entity_type_list, save_path):\n",
    "    data_origin = os.path.join(data_path, train_origin_data)\n",
    "    annotation = os.path.join(data_path, train_annotated_data)\n",
    "    with open(data_origin) as f1:\n",
    "        origin_lines = f1.readlines()\n",
    "    with open(annotation) as f2:\n",
    "        annotated_lines = f2.readlines()\n",
    "    assert len(origin_lines) == len(annotated_lines)\n",
    "    train_data = []\n",
    "    for i in range(len(origin_lines)):\n",
    "        words, tags = resolve_line(i+1, origin_lines[i], annotated_lines[i], entity_type_list)\n",
    "        train_data.append((words, tags))\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(train_data, f)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the preprocessed data existed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is loaded!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(os.path.join(data_path, \"train_data.pkl\")):\n",
    "    with open(os.path.join(data_path, \"train_data.pkl\"), \"rb\") as f:\n",
    "        train_data = pickle.load(f)\n",
    "    print('Data is loaded!')\n",
    "else:\n",
    "    train_data = read_corpora(data_path, train_origin_data,train_annotated_data, entity_type_list, os.path.join(data_path, \"train_data.pkl\"))\n",
    "    print('Data is preprocessed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocab based on the original raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(all_data,data_path):\n",
    "    lines = []\n",
    "    for path in all_data:\n",
    "        with open(os.path.join(data_path, path)) as f:\n",
    "            lines_ = f.readlines()\n",
    "        lines.extend(lines_)\n",
    "    word2idx={}\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = len(word2idx)\n",
    "    return word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab is built!\n"
     ]
    }
   ],
   "source": [
    "# Build vocab \n",
    "word_to_ix = build_vocab(all_data,data_path)\n",
    "print('Vocab is built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = \"raw_data.orig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data is loaded!\n"
     ]
    }
   ],
   "source": [
    "# set testing data\n",
    "if os.path.exists(os.path.join(data_path, test_data)):\n",
    "    with open(os.path.join(data_path, test_data), \"r\") as f:\n",
    "        test_data = f.readlines()\n",
    "print('Test data is loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data:左膝活动后疼痛10日,患者10日前活动后出现左膝关节疼痛，伴行走不便，以上下楼酸胀不适为主，平路步行可，无肿胀及关节畸形，无晨僵，无关节绞锁病史，无腰痛、下肢放射痛。近1周来关节症状无好转，无发热，无关节周围红肿。我院膝关节磁共振扫描（左）示：左膝关节半月板损伤。患者为进一步诊疗来我院，门诊以“左膝半月板损伤、左膝骨性关节炎”收入我科。患者自发病来精神、食欲可，大小便正常，体重未见明显降低。膝关节磁共振扫描（左）示（2016-6-14，北京清华长庚医院）：左膝骨关节病，外侧半月板撕裂，关节积液，滑膜炎，腘窝囊肿。,左膝关节对位如常，关节间隙略窄，关节缘、髁间棘及髌骨缘骨质增生。关节面硬化。左侧膝关节退变,实施了关节镜手术,服用了止痛类药物,使用了外用类药物,接受了康复治疗。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'test_data:{test_data[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:(['左', '膝', '活', '动', '后', '疼', '痛', '1', '0', '日', ',', '患', '者', '1', '0', '日', '前', '活', '动', '后', '出', '现', '左', '膝', '关', '节', '疼', '痛', '，', '伴', '行', '走', '不', '便', '，', '以', '上', '下', '楼', '酸', '胀', '不', '适', '为', '主', '，', '平', '路', '步', '行', '可', '，', '无', '肿', '胀', '及', '关', '节', '畸', '形', '，', '无', '晨', '僵', '，', '无', '关', '节', '绞', '锁', '病', '史', '，', '无', '腰', '痛', '、', '下', '肢', '放', '射', '痛', '。', '近', '1', '周', '来', '关', '节', '症', '状', '无', '好', '转', '，', '无', '发', '热', '，', '无', '关', '节', '周', '围', '红', '肿', '。', '我', '院', '膝', '关', '节', '磁', '共', '振', '扫', '描', '（', '左', '）', '示', '：', '左', '膝', '关', '节', '半', '月', '板', '损', '伤', '。', '患', '者', '为', '进', '一', '步', '诊', '疗', '来', '我', '院', '，', '门', '诊', '以', '“', '左', '膝', '半', '月', '板', '损', '伤', '、', '左', '膝', '骨', '性', '关', '节', '炎', '”', '收', '入', '我', '科', '。', '患', '者', '自', '发', '病', '来', '精', '神', '、', '食', '欲', '可', '，', '大', '小', '便', '正', '常', '，', '体', '重', '未', '见', '明', '显', '降', '低', '。', '膝', '关', '节', '磁', '共', '振', '扫', '描', '（', '左', '）', '示', '（', '2', '0', '1', '6', '-', '6', '-', '1', '4', '，', '北', '京', '清', '华', '长', '庚', '医', '院', '）', '：', '左', '膝', '骨', '关', '节', '病', '，', '外', '侧', '半', '月', '板', '撕', '裂', '，', '关', '节', '积', '液', '，', '滑', '膜', '炎', '，', '腘', '窝', '囊', '肿', '。', ',', '左', '膝', '关', '节', '对', '位', '如', '常', '，', '关', '节', '间', '隙', '略', '窄', '，', '关', '节', '缘', '、', '髁', '间', '棘', '及', '髌', '骨', '缘', '骨', '质', '增', '生', '。', '关', '节', '面', '硬', '化', '。', '左', '侧', '膝', '关', '节', '退', '变', ',', '实', '施', '了', '关', '节', '镜', '手', '术', ',', '服', '用', '了', '止', '痛', '类', '药', '物', ',', '使', '用', '了', '外', '用', '类', '药', '物', ',', '接', '受', '了', '康', '复', '治', '疗', '。'], ['O', 'O', 'O', 'O', 'O', 'B-S', 'I-S', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-P', 'I-P', 'O', 'O', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-S', 'I-S', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'O', 'O', 'B-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'O', 'O', 'O', 'O', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'O', 'B-D', 'I-D', 'I-D', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'O', 'O', 'O', 'O', 'O', 'B-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'O', 'B-I', 'I-I', 'I-I', 'I-I', 'I-I', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'O', 'O', 'O', 'O', 'B-T', 'I-T', 'I-T', 'I-T', 'I-T', 'O', 'O', 'O', 'O', 'B-T', 'I-T', 'I-T', 'I-T', 'I-T', 'O', 'O', 'O', 'O', 'B-T', 'I-T', 'I-T', 'I-T', 'I-T', 'O', 'O', 'O', 'O', 'B-T', 'I-T', 'I-T', 'I-T', 'O'])\n",
      "197\n",
      "2\n",
      "Data:['左', '膝', '活', '动', '后', '疼', '痛', '1', '0', '日', ',', '患', '者', '1', '0', '日', '前', '活', '动', '后', '出', '现', '左', '膝', '关', '节', '疼', '痛', '，', '伴', '行', '走', '不', '便', '，', '以', '上', '下', '楼', '酸', '胀', '不', '适', '为', '主', '，', '平', '路', '步', '行', '可', '，', '无', '肿', '胀', '及', '关', '节', '畸', '形', '，', '无', '晨', '僵', '，', '无', '关', '节', '绞', '锁', '病', '史', '，', '无', '腰', '痛', '、', '下', '肢', '放', '射', '痛', '。', '近', '1', '周', '来', '关', '节', '症', '状', '无', '好', '转', '，', '无', '发', '热', '，', '无', '关', '节', '周', '围', '红', '肿', '。', '我', '院', '膝', '关', '节', '磁', '共', '振', '扫', '描', '（', '左', '）', '示', '：', '左', '膝', '关', '节', '半', '月', '板', '损', '伤', '。', '患', '者', '为', '进', '一', '步', '诊', '疗', '来', '我', '院', '，', '门', '诊', '以', '“', '左', '膝', '半', '月', '板', '损', '伤', '、', '左', '膝', '骨', '性', '关', '节', '炎', '”', '收', '入', '我', '科', '。', '患', '者', '自', '发', '病', '来', '精', '神', '、', '食', '欲', '可', '，', '大', '小', '便', '正', '常', '，', '体', '重', '未', '见', '明', '显', '降', '低', '。', '膝', '关', '节', '磁', '共', '振', '扫', '描', '（', '左', '）', '示', '（', '2', '0', '1', '6', '-', '6', '-', '1', '4', '，', '北', '京', '清', '华', '长', '庚', '医', '院', '）', '：', '左', '膝', '骨', '关', '节', '病', '，', '外', '侧', '半', '月', '板', '撕', '裂', '，', '关', '节', '积', '液', '，', '滑', '膜', '炎', '，', '腘', '窝', '囊', '肿', '。', ',', '左', '膝', '关', '节', '对', '位', '如', '常', '，', '关', '节', '间', '隙', '略', '窄', '，', '关', '节', '缘', '、', '髁', '间', '棘', '及', '髌', '骨', '缘', '骨', '质', '增', '生', '。', '关', '节', '面', '硬', '化', '。', '左', '侧', '膝', '关', '节', '退', '变', ',', '实', '施', '了', '关', '节', '镜', '手', '术', ',', '服', '用', '了', '止', '痛', '类', '药', '物', ',', '使', '用', '了', '外', '用', '类', '药', '物', ',', '接', '受', '了', '康', '复', '治', '疗', '。']\n",
      "train label:['O', 'O', 'O', 'O', 'O', 'B-S', 'I-S', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-P', 'I-P', 'O', 'O', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-S', 'I-S', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-S', 'I-S', 'O', 'O', 'B-S', 'I-S', 'I-S', 'I-S', 'I-S', 'I-S', 'O', 'O', 'O', 'O', 'B-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'O', 'O', 'O', 'O', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'O', 'B-D', 'I-D', 'I-D', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'O', 'O', 'O', 'O', 'O', 'B-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'I-I', 'O', 'B-I', 'I-I', 'I-I', 'I-I', 'I-I', 'O', 'B-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'I-D', 'O', 'O', 'O', 'O', 'B-T', 'I-T', 'I-T', 'I-T', 'I-T', 'O', 'O', 'O', 'O', 'B-T', 'I-T', 'I-T', 'I-T', 'I-T', 'O', 'O', 'O', 'O', 'B-T', 'I-T', 'I-T', 'I-T', 'I-T', 'O', 'O', 'O', 'O', 'B-T', 'I-T', 'I-T', 'I-T', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(f'train data:{train_data[0]}')\n",
    "print(len(train_data))\n",
    "print(len(train_data[0]))\n",
    "print(f'Data:{train_data[0][0]}')\n",
    "print(f'train label:{train_data[0][1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data,tag_to_ix,to_ix,mode='Train'):\n",
    "\n",
    "        self.data = data\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.to_ix = to_ix\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        # return length\n",
    "        return len(self.data)\n",
    "\n",
    "    def make_sequence(self,sentence,to_ix):\n",
    "        idxs = [to_ix[w] for w in sentence]\n",
    "        return torch.tensor(idxs, dtype=torch.long)\n",
    "    \n",
    "    def get_label(self,tags):\n",
    "        targets = torch.tensor([self.tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "        return targets\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        \n",
    "        if self.mode == 'Train':\n",
    "            text = self.data[i][0]\n",
    "            tags = self.data[i][1]\n",
    "            seq = self.make_sequence(text,self.to_ix)\n",
    "            label = self.get_label(tags)\n",
    "            return seq, label,text\n",
    "        elif  self.mode == 'Test':\n",
    "            text = self.data[i]\n",
    "            split_text = text.strip(\"\\n\")\n",
    "            seq = self.make_sequence(split_text,self.to_ix)\n",
    "            return split_text,seq\n",
    "        else:\n",
    "            print('Wrong mode, please use \"Train\" or \"Test\" !')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size should be equal to 1, because we didn't set the fixed sequence length in this project\n",
    "# You will get error if batch size not equal to 1\n",
    "tag_to_ix = { \"O\": 0,\n",
    "              \"B-D\": 1, \"I-D\": 2,\n",
    "              \"B-S\": 3, \"I-S\": 4,\n",
    "              \"B-T\": 5, \"I-T\": 6,\n",
    "              \"B-I\": 7, \"I-I\": 8,\n",
    "              \"B-C\": 9, \"I-C\": 10,\n",
    "              \"B-A\": 11, \"I-A\": 12,\n",
    "              \"B-B\": 13, \"I-B\": 14,\n",
    "              \"B-P\": 15, \"I-P\": 16,\n",
    "              \"<START>\": 17, \"<STOP>\": 18}\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "TrainDataset = MyDataset(train_data,tag_to_ix,word_to_ix,'Train')\n",
    "TestDataset = MyDataset(test_data,tag_to_ix,word_to_ix,'Test')\n",
    "\n",
    "TrainLoader = DataLoader(TrainDataset, batch_size=batch_size, shuffle=False)\n",
    "TestLoader = DataLoader(TestDataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:0\n",
      "sentence:('左膝活动后疼痛10日,患者10日前活动后出现左膝关节疼痛，伴行走不便，以上下楼酸胀不适为主，平路步行可，无肿胀及关节畸形，无晨僵，无关节绞锁病史，无腰痛、下肢放射痛。近1周来关节症状无好转，无发热，无关节周围红肿。我院膝关节磁共振扫描（左）示：左膝关节半月板损伤。患者为进一步诊疗来我院，门诊以“左膝半月板损伤、左膝骨性关节炎”收入我科。患者自发病来精神、食欲可，大小便正常，体重未见明显降低。膝关节磁共振扫描（左）示（2016-6-14，北京清华长庚医院）：左膝骨关节病，外侧半月板撕裂，关节积液，滑膜炎，腘窝囊肿。,左膝关节对位如常，关节间隙略窄，关节缘、髁间棘及髌骨缘骨质增生。关节面硬化。左侧膝关节退变,实施了关节镜手术,服用了止痛类药物,使用了外用类药物,接受了康复治疗。',)\n",
      "seq:tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,   7,\n",
      "           8,   9,  13,   2,   3,   4,  14,  15,   0,   1,  16,  17,   5,   6,\n",
      "          18,  19,  20,  21,  22,  23,  18,  24,  25,  26,  27,  28,  29,  22,\n",
      "          30,  31,  32,  18,  33,  34,  35,  20,  36,  18,  37,  38,  29,  39,\n",
      "          16,  17,  40,  41,  18,  37,  42,  43,  18,  37,  16,  17,  44,  45,\n",
      "          46,  47,  18,  37,  48,   6,  49,  26,  50,  51,  52,   6,  53,  54,\n",
      "           7,  55,  56,  16,  17,  57,  58,  37,  59,  60,  18,  37,  61,  62,\n",
      "          18,  37,  16,  17,  55,  63,  64,  38,  53,  65,  66,   1,  16,  17,\n",
      "          67,  68,  69,  70,  71,  72,   0,  73,  74,  75,   0,   1,  16,  17,\n",
      "          76,  77,  78,  79,  80,  53,  11,  12,  31,  81,  82,  35,  83,  84,\n",
      "          56,  65,  66,  18,  85,  83,  24,  86,   0,   1,  76,  77,  78,  79,\n",
      "          80,  49,   0,   1,  87,  88,  16,  17,  89,  90,  91,  92,  65,  93,\n",
      "          53,  11,  12,  94,  61,  46,  56,  95,  96,  49,  97,  98,  36,  18,\n",
      "          99, 100,  23, 101, 102,  18, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "          53,   1,  16,  17,  67,  68,  69,  70,  71,  72,   0,  73,  74,  72,\n",
      "         111,   8,   7, 112, 113, 112, 113,   7, 114,  18, 115, 116, 117, 118,\n",
      "         119, 120, 121,  66,  73,  75,   0,   1,  87,  16,  17,  46,  18, 122,\n",
      "         123,  76,  77,  78, 124, 125,  18,  16,  17, 126, 127,  18, 128, 129,\n",
      "          89,  18, 130, 131, 132,  38,  53,  10,   0,   1,  16,  17, 133, 134,\n",
      "         135, 102,  18,  16,  17, 136, 137, 138, 139,  18,  16,  17, 140,  49,\n",
      "         141, 136, 142,  39, 143,  87, 140,  87, 144, 145, 146,  53,  16,  17,\n",
      "         147, 148, 149,  53,   0, 123,   1,  16,  17, 150, 151,  10, 152, 153,\n",
      "         154,  16,  17, 155, 156, 157,  10, 158, 159, 154, 160,   6, 161, 162,\n",
      "         163,  10, 164, 159, 154, 122, 159, 161, 162, 163,  10, 165, 166, 154,\n",
      "         167, 168, 169,  84,  53]])\n"
     ]
    }
   ],
   "source": [
    "for index, (sentence,seq) in enumerate(TestLoader):\n",
    "    print(f'index:{index}')\n",
    "    print(f'sentence:{sentence}')\n",
    "    print(f'seq:{seq}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:0\n",
      "sentence:torch.Size([1, 341])\n",
      "seq:[('左',), ('膝',), ('活',), ('动',), ('后',), ('疼',), ('痛',), ('1',), ('0',), ('日',), (',',), ('患',), ('者',), ('1',), ('0',), ('日',), ('前',), ('活',), ('动',), ('后',), ('出',), ('现',), ('左',), ('膝',), ('关',), ('节',), ('疼',), ('痛',), ('，',), ('伴',), ('行',), ('走',), ('不',), ('便',), ('，',), ('以',), ('上',), ('下',), ('楼',), ('酸',), ('胀',), ('不',), ('适',), ('为',), ('主',), ('，',), ('平',), ('路',), ('步',), ('行',), ('可',), ('，',), ('无',), ('肿',), ('胀',), ('及',), ('关',), ('节',), ('畸',), ('形',), ('，',), ('无',), ('晨',), ('僵',), ('，',), ('无',), ('关',), ('节',), ('绞',), ('锁',), ('病',), ('史',), ('，',), ('无',), ('腰',), ('痛',), ('、',), ('下',), ('肢',), ('放',), ('射',), ('痛',), ('。',), ('近',), ('1',), ('周',), ('来',), ('关',), ('节',), ('症',), ('状',), ('无',), ('好',), ('转',), ('，',), ('无',), ('发',), ('热',), ('，',), ('无',), ('关',), ('节',), ('周',), ('围',), ('红',), ('肿',), ('。',), ('我',), ('院',), ('膝',), ('关',), ('节',), ('磁',), ('共',), ('振',), ('扫',), ('描',), ('（',), ('左',), ('）',), ('示',), ('：',), ('左',), ('膝',), ('关',), ('节',), ('半',), ('月',), ('板',), ('损',), ('伤',), ('。',), ('患',), ('者',), ('为',), ('进',), ('一',), ('步',), ('诊',), ('疗',), ('来',), ('我',), ('院',), ('，',), ('门',), ('诊',), ('以',), ('“',), ('左',), ('膝',), ('半',), ('月',), ('板',), ('损',), ('伤',), ('、',), ('左',), ('膝',), ('骨',), ('性',), ('关',), ('节',), ('炎',), ('”',), ('收',), ('入',), ('我',), ('科',), ('。',), ('患',), ('者',), ('自',), ('发',), ('病',), ('来',), ('精',), ('神',), ('、',), ('食',), ('欲',), ('可',), ('，',), ('大',), ('小',), ('便',), ('正',), ('常',), ('，',), ('体',), ('重',), ('未',), ('见',), ('明',), ('显',), ('降',), ('低',), ('。',), ('膝',), ('关',), ('节',), ('磁',), ('共',), ('振',), ('扫',), ('描',), ('（',), ('左',), ('）',), ('示',), ('（',), ('2',), ('0',), ('1',), ('6',), ('-',), ('6',), ('-',), ('1',), ('4',), ('，',), ('北',), ('京',), ('清',), ('华',), ('长',), ('庚',), ('医',), ('院',), ('）',), ('：',), ('左',), ('膝',), ('骨',), ('关',), ('节',), ('病',), ('，',), ('外',), ('侧',), ('半',), ('月',), ('板',), ('撕',), ('裂',), ('，',), ('关',), ('节',), ('积',), ('液',), ('，',), ('滑',), ('膜',), ('炎',), ('，',), ('腘',), ('窝',), ('囊',), ('肿',), ('。',), (',',), ('左',), ('膝',), ('关',), ('节',), ('对',), ('位',), ('如',), ('常',), ('，',), ('关',), ('节',), ('间',), ('隙',), ('略',), ('窄',), ('，',), ('关',), ('节',), ('缘',), ('、',), ('髁',), ('间',), ('棘',), ('及',), ('髌',), ('骨',), ('缘',), ('骨',), ('质',), ('增',), ('生',), ('。',), ('关',), ('节',), ('面',), ('硬',), ('化',), ('。',), ('左',), ('侧',), ('膝',), ('关',), ('节',), ('退',), ('变',), (',',), ('实',), ('施',), ('了',), ('关',), ('节',), ('镜',), ('手',), ('术',), (',',), ('服',), ('用',), ('了',), ('止',), ('痛',), ('类',), ('药',), ('物',), (',',), ('使',), ('用',), ('了',), ('外',), ('用',), ('类',), ('药',), ('物',), (',',), ('接',), ('受',), ('了',), ('康',), ('复',), ('治',), ('疗',), ('。',)]\n",
      "tags:tensor([[ 0,  0,  0,  0,  0,  3,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 15,\n",
      "         16,  0,  0,  0,  3,  4,  4,  4,  4,  4,  0,  0,  3,  4,  4,  4,  0,  0,\n",
      "          3,  4,  4,  4,  4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,\n",
      "          4,  0,  3,  4,  4,  4,  0,  0,  3,  4,  0,  0,  3,  4,  4,  4,  4,  4,\n",
      "          0,  0,  3,  4,  0,  3,  4,  4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  3,  4,  0,  0,  3,  4,  4,  4,  4,  4,  0,  0,\n",
      "          0,  0,  9, 10, 10, 10, 10, 10, 10,  0,  0,  0,  0,  0,  1,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  1,  2,  2,  2,  2,  2,  2,  0,  1,  2,  2,  2,  2,  2,\n",
      "          2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  9,\n",
      "         10, 10, 10, 10, 10, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  2,\n",
      "          2,  2,  0,  1,  2,  2,  2,  2,  2,  2,  0,  1,  2,  2,  2,  0,  1,  2,\n",
      "          2,  0,  1,  2,  2,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  7,\n",
      "          8,  8,  8,  8,  8,  0,  0,  0,  0,  0,  7,  8,  8,  8,  8,  8,  8,  8,\n",
      "          8,  8,  8,  0,  7,  8,  8,  8,  8,  0,  1,  2,  2,  2,  2,  2,  2,  0,\n",
      "          0,  0,  0,  5,  6,  6,  6,  6,  0,  0,  0,  0,  5,  6,  6,  6,  6,  0,\n",
      "          0,  0,  0,  5,  6,  6,  6,  6,  0,  0,  0,  0,  5,  6,  6,  6,  0]])\n",
      "cache shape:torch.Size([341])\n"
     ]
    }
   ],
   "source": [
    "for index, (sentence, label,seq) in enumerate(TrainLoader):\n",
    "    print(f'index:{index}')\n",
    "    print(f'sentence:{sentence.shape}')\n",
    "    print(f'seq:{seq}')\n",
    "    print(f'tags:{label}')\n",
    "    cache = sentence.squeeze(0)\n",
    "    print(f'cache shape:{cache.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim,hidden_dim,cuda_tag=False):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.device = \"cuda:0\" if cuda_tag else \"cpu\" \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        self.hidden2tag = nn.Linear(self.hidden_dim, self.tagset_size)\n",
    "\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size)).to(self.device)\n",
    "\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2).to(self.device),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2).to(self.device))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000., device=self.device)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "\n",
    "                alphas_t.append(torch.logsumexp(next_tag_var,dim=1).view(1))\n",
    "\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = torch.logsumexp(terminal_var,dim=1)[0]\n",
    "\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1).to(self.device)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long, device=self.device), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.,device=self.device)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "\n",
    "                best_tag_id = torch.argmax(next_tag_var).item()\n",
    "\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "\n",
    "        best_tag_id = torch.argmax(terminal_var).item()\n",
    "\n",
    "\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model = \"\"\n",
    "\n",
    "embedding_dim = 300\n",
    "hidden_dim = 600\n",
    "cuda_tag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model is created!\n",
      "Model initialization is done!\n",
      "Use cpu to train\n"
     ]
    }
   ],
   "source": [
    "# init model for training\n",
    "if init_model != str(\"\"):\n",
    "    model = torch.load(os.path.join(data_path, init_model))\n",
    "    print('Model loading is done!')\n",
    "else:\n",
    "    model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, embedding_dim,hidden_dim,cuda_tag)\n",
    "    print('New model is created!')\n",
    "if cuda_tag:\n",
    "    model = model.cuda() \n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\" \n",
    "\n",
    "print('Model initialization is done!')\n",
    "print('Use %s to train'%device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cpu\n",
      "iteration 0/197 completed, loss: 1073.4303\n",
      "iteration 20/197 completed, loss: 196.7087\n",
      "iteration 40/197 completed, loss: 347.7083\n",
      "iteration 60/197 completed, loss: 4.6668\n",
      "iteration 80/197 completed, loss: 77.8952\n",
      "iteration 100/197 completed, loss: 333.7498\n",
      "iteration 120/197 completed, loss: 324.1519\n",
      "iteration 140/197 completed, loss: 181.4973\n",
      "iteration 160/197 completed, loss: 137.3928\n",
      "iteration 180/197 completed, loss: 73.8999\n",
      "epoch 1/1 completed, loss: 247.7454\n",
      "Model is saved!\n"
     ]
    }
   ],
   "source": [
    "# train and save model \n",
    "print(f'device:{device}')\n",
    "\n",
    "epoch_num = 1\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    # for index, (sentence, tags) in enumerate(train_data):\n",
    "    for index, (sentence, tags,_) in enumerate(TrainLoader):\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Inputs ready for the network, that is,turn them into Tensors of word indices.\n",
    "\n",
    "        # sentence_in = prepare_sequence_torch(sentence, word_to_ix).to(device)\n",
    "        # targets = torch.tensor([tag_to_ix[t[0]] for t in tags], dtype=torch.long).to(device)\n",
    "        # print(f'sentence shape:{sentence.shape}')\n",
    "        sentence_in = sentence.squeeze(0).to(device)\n",
    "        targets = tags.squeeze(0).to(device)\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if index % 20 == 0:\n",
    "            print(\"iteration {}/{} completed, loss: {:.4f}\".format(index, len(train_data), loss.item()))\n",
    "    print(\"epoch {}/{} completed, loss: {:.4f}\".format(epoch+1, epoch_num, loss.item()))\n",
    "\n",
    "with open(os.path.join(data_path, \"model.pkl\"), \"wb\") as f:\n",
    "    torch.save(model, f)\n",
    "print('Model is saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tags(sent, ixs, ix_to_tag):\n",
    "    tags = []\n",
    "    # print(f'ixs:{ixs}')\n",
    "    # print(f'ix_to_tag:{ix_to_tag}')\n",
    "    for ix in ixs:\n",
    "        tags.append(ix_to_tag[ix])\n",
    "\n",
    "    # correct the annotated tags for the sentence\n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag[0] == \"I\" and not (tags[i - 1] == str(\"B-\" + tag[-1]) or tags[i - 1] == tag):\n",
    "            tags[i] = \"O\"\n",
    "    \n",
    "    # output the annotated sentence\n",
    "    i = 0\n",
    "    output = []\n",
    "    while i < len(tags):\n",
    "        if tags[i][0] == \"B\":\n",
    "            output.append(\" \")\n",
    "            end = i + 1\n",
    "            while end < len(tags) and tags[end] == \"I\" + tags[i][1: ]:\n",
    "                end += 1\n",
    "            output.extend(sent[i: end]) \n",
    "            output.append(\"\\\\\" + tags[i][-1].lower() + \" \")\n",
    "            i = end\n",
    "        else:\n",
    "            output.extend(sent[i])\n",
    "            i += 1\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/446 items complete testing\n",
      "20/446 items complete testing\n",
      "40/446 items complete testing\n",
      "60/446 items complete testing\n",
      "80/446 items complete testing\n",
      "100/446 items complete testing\n",
      "120/446 items complete testing\n",
      "140/446 items complete testing\n",
      "160/446 items complete testing\n",
      "180/446 items complete testing\n",
      "200/446 items complete testing\n",
      "220/446 items complete testing\n",
      "240/446 items complete testing\n",
      "260/446 items complete testing\n",
      "280/446 items complete testing\n",
      "300/446 items complete testing\n",
      "320/446 items complete testing\n",
      "340/446 items complete testing\n",
      "360/446 items complete testing\n",
      "380/446 items complete testing\n",
      "400/446 items complete testing\n",
      "420/446 items complete testing\n",
      "440/446 items complete testing\n",
      "Output file is saved!\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "test_output = \"output\"\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    ix_to_tag = {} \n",
    "    for key in tag_to_ix:\n",
    "        ix_to_tag[tag_to_ix[key]] = key\n",
    "    # print(f'ix_to_tag:{ix_to_tag}')\n",
    "    annotated_lines = []\n",
    "    for index, (line,seq) in enumerate(TestLoader):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            encoded_sent = seq.squeeze(0)\n",
    "            tag_ixs = model(encoded_sent)[1]\n",
    "            annotated_line = decode_tags(line[0].strip(\"\\n\"), tag_ixs, ix_to_tag) \n",
    "        annotated_lines.append(annotated_line.strip() + \"\\n\")\n",
    "        if index % 20 == 0:\n",
    "            print(\"{}/{} items complete testing\".format(index, len(test_data)))\n",
    "\n",
    "with open(os.path.join(data_path, test_output), \"w\") as f:\n",
    "    for line in annotated_lines:\n",
    "        f.write(line)\n",
    "print('Output file is saved!')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15ada863ba5d8596ec241140439045809b47de0161a1b82a0e7ba4b5571a9dbf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
